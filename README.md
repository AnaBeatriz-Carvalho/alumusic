# üéµ AluMusic Insights

## Sobre o Projeto

**AluMusic Insights** √© uma plataforma de an√°lise de dados projetada para processar e extrair insights valiosos a partir de milhares de coment√°rios de ouvintes. A solu√ß√£o foi desenvolvida como parte de um desafio t√©cnico para a Alura, com foco em Python, Grandes Modelos de Linguagem (LLMs) e arquitetura de sistemas escal√°veis.

O servi√ßo ingere coment√°rios em lote, utiliza a API do Google Gemini para realizar uma classifica√ß√£o de sentimento e extra√ß√£o de tags, e apresenta os resultados em um dashboard privado para an√°lise e em um relat√≥rio p√∫blico em tempo real.

## ‚ú® Funcionalidades Principais

* **Ingest√£o Ass√≠ncrona de Dados:** Um endpoint de API REST (`/api/comentarios`) protegido por JWT que recebe lotes de coment√°rios e os enfileira para processamento em background, garantindo alta disponibilidade e resposta r√°pida ao cliente.
* **Processamento com IA:** Utiliza√ß√£o do Celery e Redis para gerenciar uma fila de tarefas, onde workers processam cada coment√°rio individualmente, chamando a API do Google Gemini para classifica√ß√£o e extra√ß√£o de tags.
* **Dashboard Privado Interativo:** Uma interface constru√≠da com Streamlit para a equipe de curadoria, protegida por login, que permite buscar, filtrar, visualizar o hist√≥rico de classifica√ß√µes e exportar os dados em formatos CSV e JSON.
* **Relat√≥rio P√∫blico em Tempo Real:** Uma p√°gina p√∫blica que exibe 5 visualiza√ß√µes de dados com os insights mais recentes, com um sistema de cache no Redis que garante que os dados sejam atualizados a cada 60 segundos sem sobrecarregar o banco de dados.
* **Avalia√ß√£o de Performance da IA:** Um fluxo de avalia√ß√£o de ponta a ponta, automatizado com Pytest, que mede a qualidade da classifica√ß√£o do modelo atrav√©s de m√©tricas como Acur√°cia, Precis√£o, Recall, F1-Score e uma Matriz de Confus√£o.

## üèõÔ∏è Arquitetura

O sistema √© composto por microsservi√ßos containerizados e orquestrados com Docker Compose, seguindo uma arquitetura desacoplada e escal√°vel.

```mermaid
graph TD
    subgraph "Cliente Externo"
        A[Script de Carga / Outro Servi√ßo]
    end

    subgraph "Navegador do Usu√°rio"
        B[Dashboard Streamlit]
        C[Relat√≥rio P√∫blico]
    end

    subgraph "Infraestrutura Docker"
        D[API Flask]
        E[Worker Celery]
        F[Banco de Dados PostgreSQL]
        G[Fila e Cache Redis]
    end

    subgraph "Servi√ßo Externo"
        H[API Google Gemini]
    end

    A -- JSON em lote --> D
    B -- Requisi√ß√µes c/ JWT --> D
    C -- Requisi√ß√µes p√∫blicas --> D

    D -- Enfileira Tarefas --> G
    D -- Salva/L√™ Dados --> F
    D -- L√™ Cache do Relat√≥rio --> G

    E -- Pega Tarefas --> G
    E -- Chama API --> H
    E -- Salva Resultados --> F
```

## üõ†Ô∏è Tech Stack

* **Backend:** Flask, SQLAlchemy
* **Frontend (Dashboard):** Streamlit
* **Banco de Dados:** PostgreSQL
* **Fila e Cache:** Celery, Redis
* **Intelig√™ncia Artificial:** Google Gemini (via `google-generativeai`)
* **Visualiza√ß√£o de Dados:** Pandas, Matplotlib
* **Testes e M√©tricas:** Pytest, Scikit-learn
* **Containeriza√ß√£o:** Docker, Docker Compose

## üöÄ Como Executar o Projeto

Siga os passos abaixo para configurar e rodar a aplica√ß√£o localmente.

### Pr√©-requisitos

* [Docker](https://www.docker.com/get-started)
* [Docker Compose](https://docs.docker.com/compose/install/)

### 1. Configura√ß√£o do Ambiente

1.  Clone este reposit√≥rio:
    ```bash
    git clone [URL_DO_SEU_REPOSITORIO]
    cd nome-do-repositorio
    ```

2.  Crie uma c√≥pia do arquivo de exemplo de vari√°veis de ambiente:
    ```bash
    cp .env.example .env
    ```

3.  Abra o arquivo `.env` e preencha as vari√°veis. A mais importante √© a sua chave da API do Google Gemini:
    ```env
    # Chave secreta para o Flask e JWT
    SECRET_KEY="uma_chave_super_secreta_aqui"
    JWT_SECRET_KEY="outra_chave_super_secreta_aqui"

    # Credenciais do Banco de Dados PostgreSQL
    POSTGRES_USER=alumusic
    POSTGRES_PASSWORD=alumusic
    POSTGRES_DB=alumusic

    # URL de conex√£o para a aplica√ß√£o (n√£o altere o host 'alumusic')
    DATABASE_URL=postgresql://alumusic:alumusic@alumusic:5432/alumusic

    # URL do Broker para o Celery (n√£o altere o host 'redis')
    CELERY_BROKER_URL=redis://redis:6379/0
    CELERY_RESULT_BACKEND=redis://redis:6379/0

    # Chave da API do Google Gemini
    GOOGLE_API_KEY="AIzaSy..."
    ```

### 2. Executando a Aplica√ß√£o

Com o Docker em execu√ß√£o, suba todos os servi√ßos com um √∫nico comando:
```bash
docker-compose up --build -d
```
O comando `--build` √© importante na primeira vez para construir a imagem Docker. O `-d` executa os cont√™ineres em segundo plano.

### 3. Acessando e Usando a Aplica√ß√£o

* **Dashboard Privado:** Acesse `http://localhost:8501` no seu navegador.
    * Use a aba "Registrar" na barra lateral para criar uma conta para a equipe de curadoria.
    * Ap√≥s o registro, fa√ßa o login para acessar o dashboard de an√°lise.

* **Relat√≥rio P√∫blico:** A aba "Relat√≥rio P√∫blico" pode ser acessada sem login e √© atualizada a cada 60 segundos.

---
### 4. Avalia√ß√£o e M√©tricas

O projeto inclui um fluxo de avalia√ß√£o automatizado para medir a performance do modelo de classifica√ß√£o de ponta a ponta.

#### Comando de Execu√ß√£o

Para rodar os testes e gerar o relat√≥rio de m√©tricas, execute o seguinte comando √∫nico na raiz do projeto:
```bash
docker-compose exec api pytest -m e2e -sv
```
*(**Nota:** Certifique-se de que o usu√°rio de teste definido em `tests/evals/test_classification_pipeline.py` j√° foi registrado na aplica√ß√£o.)*

#### O Que o Comando Faz

Este comando orquestra o seguinte fluxo:
1.  Carrega um dataset de teste ("gabarito") a partir de `tests/evals/dataset.json`.
2.  Envia os dados para a API e aguarda o processamento em background pelos workers do Celery.
3.  Busca os resultados processados diretamente do banco de dados.
4.  Compara os resultados da IA com o gabarito.
5.  Imprime um relat√≥rio detalhado no console com m√©tricas de **Acur√°cia, Precis√£o, Recall, F1-Score** e uma **Matriz de Confus√£o**.

---
### ‚öñÔ∏è Principais Decis√µes de Design

* **API Ass√≠ncrona com Celery/Redis:** A escolha de uma arquitetura ass√≠ncrona foi fundamental –¥–ª—è atender ao requisito de processamento de grandes lotes sem degradar a experi√™ncia do cliente. A API pode aceitar centenas de coment√°rios instantaneamente, enfileirando o trabalho pesado para os workers.
* **Frontend Desacoplado com Streamlit:** Streamlit foi escolhido pela sua capacidade de criar rapidamente dashboards de dados interativos e visualmente ricos, ideal para o p√∫blico-alvo da ferramenta (equipe de curadoria). A comunica√ß√£o via API REST mant√©m o frontend e o backend desacoplados.
* **Cache para Relat√≥rio em Tempo Real:** Optou-se por uma estrat√©gia de cache-on-demand na rota p√∫blica. Isso simplifica a arquitetura, mas ainda cumpre o requisito de atualiza√ß√£o de 60 segundos, garantindo performance e baixo custo de consulta.
* **Servi√ßo de LLM Isolado (`llm_service.py`):** Toda a l√≥gica de intera√ß√£o com o Gemini, incluindo a engenharia de prompt, foi centralizada em um √∫nico m√≥dulo. Isso torna o sistema mais modular, f√°cil de testar e permite trocar o modelo de IA no futuro com impacto m√≠nimo no resto da aplica√ß√£o.
* **Testes de Ponta a Ponta (E2E) com Pytest:** O fluxo de avalia√ß√£o foi desenhado n√£o apenas para testar a fun√ß√£o de classifica√ß√£o isoladamente, mas para validar toda a pipeline: da ingest√£o na API, passando pela fila do Celery, o processamento do worker e a persist√™ncia no banco. Isso garante que o sistema funciona como um todo.

---
### üîÆ Pr√≥ximos Passos (N√£o Implementados)

* **Resumo semanal por e-mail:** Implementar uma tarefa agendada (com Celery Beat) para, ao final da semana, usar a LLM para gerar um resumo das tend√™ncias e enviar por e-mail.
* **Mini Insight-Q&A:** Adicionar a rota autenticada `/insights/perguntar` para permitir que stakeholders fa√ßam perguntas em linguagem natural sobre os dados recentes.