# üéµ AluMusic Insights



## Apresenta√ß√£o e resultados do case

AluMusic Insights foi desenvolvido para demonstrar uma pipeline pr√°tica e escal√°vel para processamento de feedback de ouvintes. O case mostra como integrar LLMs na an√°lise de texto, mantendo confiabilidade operacional com processamento ass√≠ncrono.

Resultados esperados / demonstrados:
- Classifica√ß√£o autom√°tica de coment√°rios em categorias (ELOGIO, CR√çTICA, SUGEST√ÉO, D√öVIDA, SPAM).
- Extra√ß√£o de tags relevantes por coment√°rio (t√≥picos/assuntos).
- Persist√™ncia de coment√°rios e hist√≥rico consult√°vel via dashboard e API.
- Processamento ass√≠ncrono (Celery) permitindo ingest√£o em lote sem bloquear a API.
- Gera√ß√£o de resumos semanais via LLM e persist√™ncia do resumo (envio por email foi removido conforme pedido do usu√°rio).

---

## Funcionalidades principais
- API REST (Flask) para registro/login, ingest√£o de coment√°rios e endpoint de an√°lise por LLM (`POST /api/llm/analyze`).
- Dashboard Streamlit privado para curadores, com upload (.csv/.json) e envio de texto bruto para an√°lise por LLM.
- Hist√≥rico de coment√°rios com filtros, exporta√ß√£o CSV/JSON, e exibi√ß√£o de tags e classifica√ß√£o.
- Workers Celery que processam coment√°rios individualmente e atualizam a base de dados.
- Tarefa agendada (`weekly_summary_task`) para gerar e persistir sum√°rios semanais usando o LLM; emails autom√°ticos foram removidos ‚Äî os resumos ficam dispon√≠veis via API/admin.

---

## Pr√©-requisitos
- Docker Desktop + Docker Compose (recomendado)
-  Python 3.10+ com PostgreSQL e Redis localmente instalados (opcional)

Recomendado (para Windows PowerShell):
- PowerShell 7+ (opcional, mas mais moderno)
- Suficiente mem√≥ria/CPU para rodar containers (m√≠nimo 2 CPUs e 4GB RAM para desenvolvimento)

---

## Execu√ß√£o com Docker Compose (recomendado)
Abaixo est√£o instru√ß√µes orientadas para Windows PowerShell.

1) Clone o reposit√≥rio

```powershell
git clone <URL_DO_REPOSITORIO>
cd alumusic
```

2) Crie um arquivo `.env` na raiz com as vari√°veis necess√°rias (exemplo m√≠nimo):

```ini
SECRET_KEY="uma_chave_secreta"
JWT_SECRET_KEY="uma_chave_jwt"
POSTGRES_USER=alumusic
POSTGRES_PASSWORD=alumusic
POSTGRES_DB=alumusic
DATABASE_URL=postgresql://alumusic:alumusic@alumusic:5432/alumusic
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0
GOOGLE_API_KEY="SUA_CHAVE_GOOGLE_GEMINI"
```

---

3) Suba os servi√ßos com Docker Compose

No PowerShell (na pasta do projeto):

```powershell
docker-compose up --build -d
```

Servi√ßos principais (nomeados no compose):
- `api` ‚Äî Flask + Gunicorn (API REST)
- `worker` ‚Äî Celery worker
- `beat` ‚Äî Celery Beat (scheduler para weekly_summary_task)
- `streamlit` ‚Äî Streamlit dashboard (porta 8501)
- `alumusic` / `postgres` ‚Äî PostgreSQL
- `redis` ‚Äî Redis (broker/result backend)

4) Acessos
- Streamlit (dashboard privado): http://localhost:8501
- API (externa/local): dependendo do compose, o container pode mapear porta 5001 -> 5000; verifique `docker-compose.yml`.

5) Logs e comandos √∫teis (PowerShell)

Ver logs do API:

```powershell
docker-compose logs -f api
```

Entrar no shell do servi√ßo (ex.: para rodar migra√ß√µes manualmente):

```powershell
docker-compose exec api bash
# dentro do container
flask db upgrade
```

---

## Execu√ß√£o local (sem Docker) ‚Äî breve
1) Crie virtualenv e instale depend√™ncias:

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

2) Configure vari√°veis de ambiente (ou use `.env` loader) e garanta PostgreSQL + Redis rodando localmente.
3) Rode migra√ß√µes:

```powershell
flask db upgrade
```

4) Inicie a API e o worker separadamente (em terminais distintos):

```powershell
# API
flask run --host=0.0.0.0 --port=5000
# Worker (novo terminal)
celery -A celery_app.celery worker --loglevel=info
# Beat (opcional)
celery -A celery_app.celery beat --loglevel=info
```

---

## Tests & Evals
O projeto cont√©m testes pytest. Em particular h√° um E2E de classifica√ß√£o em `tests/evals/test_classification_pipeline.py`.

Rodando os testes dentro do container `api` (compose):

```powershell
docker-compose exec api pytest -q
# ou apenas os evals

```

Observa√ß√µes sobre o teste E2E:
- O E2E carrega `tests/evals/dataset.json` e envia coment√°rios para a API, aguarda processamento e valida classifica√ß√µes.
- Os testes E2E podem esperar alguns minutos (o tempo depende do processamento dos workers).

Rodando testes localmente:

```powershell
# com venv ativado e servi√ßos DB/Redis locais
pytest -q
```

---

## Endpoints importantes (resumo)
- POST /auth/register ‚Äî registrar novo usu√°rio
- POST /auth/login ‚Äî autenticar e receber JWT
- GET /api/comentarios ‚Äî listar coment√°rios com filtros
- POST /api/llm/analyze ‚Äî enviar arquivo (.csv/.json) ou texto para an√°lise por LLM
- GET /api/tasks/<task_id> ‚Äî checar status de uma tarefa enfileirada (quando aplic√°vel)
- GET /admin/weekly_summary/latest ‚Äî buscar o √∫ltimo WeeklySummary persistido (JWT necess√°rio)

---

## Principais decis√µes de design
1. Assincronismo com Celery + Redis
- Raz√£o: processamento de centenas/milhares de coment√°rios deve ser feito fora do request cycle.
- Como: API persiste Comentario com status PENDENTE e enfileira task por coment√°rio. Workers processam e atualizam o registro.

2. Servi√ßo LLM centralizado (`app/core/llm_service.py`)
- Raz√£o: separa prompts, chamadas √† API do provedor (Gemini) e parsing; facilita troca de modelo no futuro.

3. Arquitetura simples de front/back
- Streamlit como frontend independente que consome a API, reduz acoplamento e facilita deploy independente.

4. Migra√ß√µes e versionamento (Alembic)
- Notas: as revis√µes de migration devem ter ids curtas (varchar(32) no alembic_version). Evite nomes muito longos que causem erros no banco.


---

## Troubleshooting comum
- Erro Alembic: "Can't locate revision..."
  - Certifique-se de que o container de migrate/construa a imagem depois de atualizar as migrations: `docker-compose build --no-cache migrate && docker-compose up -d migrate` ou apenas `docker-compose up --build -d`.
- Erro DataError: value too long for type character varying(32)
  - Renomeie/recrie a revis√£o para uma id curta (<=32 chars).
- Streamlit: depois de enviar um arquivo, o uploader n√£o some
  - A interface j√° foi ajustada para limpar o uploader usando uma chave din√¢mica de widget; atualize a p√°gina/clear cache do browser se necess√°rio.

---

## Observa√ß√µes operacionais
- As credenciais da API LLM (Google Gemini) devem ser adicionadas via `GOOGLE_API_KEY` como vari√°vel de ambiente.

---


## Contato
Se precisar de ajuda para rodar o projeto ou adaptar para produ√ß√£o, descreva o ambiente (local/Docker/Kubernetes) e os erros/logs que surgirem.

---

Arquivo gerado automaticamente: README.md ‚Äî atualizado para refletir o estado atual do projeto (branch: alumusic-refactor).

