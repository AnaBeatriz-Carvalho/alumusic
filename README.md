# üéµ AluMusic Insights - An√°lise de Feedback com IA

## 1. Apresenta√ß√£o e Resultados

**AluMusic Insights** √© uma plataforma de an√°lise de dados projetada para processar e extrair insights valiosos a partir de milhares de coment√°rios de ouvintes. A solu√ß√£o foi desenvolvida como parte de um desafio t√©cnico da Alura, com foco em **Python**, **Grandes Modelos de Linguagem (LLMs)** e arquitetura de sistemas escal√°veis.

O sistema ingere coment√°rios em lote, utiliza a API do **Google Gemini** para classifica√ß√£o de sentimento e extra√ß√£o de tags, e apresenta os resultados em um **dashboard privado** e em um **relat√≥rio p√∫blico em tempo real**. Nos testes de avalia√ß√£o, o sistema demonstrou uma **acur√°cia de 97%** na classifica√ß√£o de categorias em um dataset de 100 exemplos, validado por um pipeline de testes automatizado.

---

## ‚ú® Funcionalidades Principais

- **Ingest√£o Ass√≠ncrona de Dados**: Um endpoint de API REST (`/api/comentarios`) protegido por JWT que recebe lotes de coment√°rios e os enfileira para processamento em background.
- **Processamento com IA**: Utiliza√ß√£o do **Celery** e **Redis** para gerenciar uma fila de tarefas, onde workers processam cada coment√°rio individualmente, chamando a API do **Google Gemini** (`gemini-1.5-flash-latest`).
- **Dashboard Privado Interativo**: Uma interface moderna constru√≠da com **Streamlit**, protegida por login, que permite buscar, filtrar, visualizar o hist√≥rico de classifica√ß√µes e exportar os dados em formatos CSV e JSON.
- **Relat√≥rio P√∫blico em Tempo Real**: Uma p√°gina p√∫blica que exibe 6 visualiza√ß√µes de dados com os insights mais recentes, com um sistema de cache no Redis que garante que os dados sejam atualizados a cada 60 segundos.
- **Avalia√ß√£o de Performance da IA**: Um fluxo de avalia√ß√£o de ponta a ponta, automatizado com **Pytest**, que mede a qualidade da classifica√ß√£o do modelo.

---

## üèõÔ∏è Arquitetura e Estrutura

O projeto √© organizado de forma modular para separar as responsabilidades e facilitar a manuten√ß√£o. O sistema √© composto por servi√ßos containerizados e orquestrados com **Docker Compose**, seguindo uma arquitetura desacoplada e escal√°vel.

```mermaid
graph TD
    subgraph "Cliente Externo / Testes"
        A[Script de Carga / Pytest]
    end
    subgraph "Navegador do Usu√°rio"
        B[Dashboard Streamlit]
    end
    subgraph "Infraestrutura Docker"
        D[API Flask]
        E[Worker Celery]
        F[Banco de Dados PostgreSQL]
        G[Fila e Cache Redis]
    end
    subgraph "Servi√ßo Externo"
        H[API Google Gemini]
    end
    A -- JSON em lote c/ JWT --> D
    B -- Requisi√ß√µes REST c/ JWT --> D
    D -- Enfileira Tarefas --> G
    D -- Salva/L√™ Dados --> F
    D -- L√™/Escreve Cache do Relat√≥rio --> G
    E -- Pega Tarefas --> G
    E -- Chama API --> H
    E -- Salva Resultados --> F
```

---

## üõ†Ô∏è Tech Stack

- **Linguagem Principal**: Python (3.10+)
- **Backend**: Flask, SQLAlchemy
- **Frontend (Dashboard)**: Streamlit
- **Banco de Dados**: PostgreSQL
- **Fila e Cache**: Celery, Redis
- **Intelig√™ncia Artificial**: Google Gemini (via `google-generativeai`)
- **Visualiza√ß√£o de Dados**: Pandas, Matplotlib
- **Testes e M√©tricas**: Pytest, Scikit-learn
- **Containeriza√ß√£o**: Docker, Docker Compose

---

## üöÄ Como Executar o Projeto

### 1. Pr√©-requisitos

- **Docker**
- **Docker Compose**

### 2. Configura√ß√£o

Clone o reposit√≥rio e entre na branch correta:

```bash
git clone https://github.com/AnaBeatriz-Carvalho/alumusic.git
cd alumusic
```

Crie o arquivo `.env` a partir do exemplo:

```bash
cp .env.example .env
```

Abra o arquivo `.env` e preencha as vari√°veis, especialmente a sua `GOOGLE_API_KEY`.

### 3. Execu√ß√£o

Com o Docker em execu√ß√£o, suba todos os servi√ßos. O banco de dados ser√° criado e as migra√ß√µes ser√£o aplicadas automaticamente:

```bash
docker-compose up --build -d
```

Acesse o dashboard em [http://localhost:8501](http://localhost:8501) no seu navegador.

### 4. Avalia√ß√£o e M√©tricas

O projeto inclui um fluxo de avalia√ß√£o automatizado para medir a performance do modelo de classifica√ß√£o.

#### Comando de Execu√ß√£o

Para rodar os testes e gerar o relat√≥rio de m√©tricas, execute o seguinte comando √∫nico:

```bash
docker-compose exec api pytest -m e2e -sv
```

#### Resultado Esperado

O comando ir√° orquestrar todo o fluxo de teste e, ao final, imprimir um relat√≥rio detalhado no console, similar a este:

```
============================================================
 Relat√≥rio Final de Avalia√ß√£o da Pipeline de Classifica√ß√£o =
============================================================

>>> M√©tricas de Classifica√ß√£o de Categoria:
              precision    recall  f1-score   support
     CR√çTICA       1.00      0.97      0.98        31
      D√öVIDA       1.00      0.95      0.97        20
...
    accuracy                           0.97        98

>>> Matriz de Confus√£o (Real vs. Previsto):
               Prev: CR√çTICA  Prev: D√öVIDA ...
Real: CR√çTICA             30             0
Real: D√öVIDA               0            19

>>> M√©tricas de Extra√ß√£o de Tags:
Acur√°cia de Tags (correspond√™ncia exata): 10.20%
```

---

## ‚öñÔ∏è Principais Decis√µes de Design

- **API Ass√≠ncrona com Celery/Redis**: A escolha de uma arquitetura ass√≠ncrona foi fundamental para atender ao requisito de processamento de grandes lotes. A API pode aceitar centenas de coment√°rios instantaneamente, enfileirando o trabalho pesado para os workers.
- **Frontend Desacoplado com Streamlit**: Streamlit foi escolhido pela sua capacidade de criar rapidamente dashboards de dados interativos. A comunica√ß√£o via API REST mant√©m o frontend e o backend desacoplados, e o uso de um arquivo `.css` externo permitiu a cria√ß√£o de um design moderno e customizado.
- **Cache para Relat√≥rio em Tempo Real**: Optou-se por uma estrat√©gia de cache-on-demand na rota p√∫blica. A pr√≥pria API gera o relat√≥rio se o cache do Redis estiver expirado (60s). Isso simplifica a arquitetura (removendo a necessidade do Celery Beat para esta fun√ß√£o), mas ainda cumpre o requisito de atualiza√ß√£o.
- **Servi√ßo de LLM Isolado e Refinado**: Toda a l√≥gica de intera√ß√£o com o Gemini, incluindo a engenharia de prompt, foi centralizada no m√≥dulo `llm_service.py`. O prompt foi aprimorado com t√©cnicas de "Few-Shot Prompting" para aumentar a consist√™ncia e a acur√°cia na extra√ß√£o de tags.
- **Testes de Ponta a Ponta (E2E) com Pytest**: O fluxo de avalia√ß√£o foi desenhado para validar toda a pipeline: da ingest√£o na API, passando pela fila do Celery, o processamento do worker e a persist√™ncia no banco, fornecendo m√©tricas realistas.

---

## üó∫Ô∏è Endpoints Principais da API

- **POST** `/auth/register`: Registra um novo usu√°rio da equipe.
- **POST** `/auth/login`: Autentica um usu√°rio e retorna um token JWT.
- **POST** `/api/comentarios`: Recebe um lote de coment√°rios para processamento.
- **GET** `/api/comentarios`: Lista os coment√°rios processados, com suporte a filtros.
- **GET** `/api/comentarios/<uuid>`: Retorna os detalhes de um coment√°rio espec√≠fico.
- **GET** `/api/relatorio/semana`: Rota p√∫blica que retorna os dados do relat√≥rio em tempo real.

---

## üìû Contato

**Ana Beatriz Carvalho Oliveira**  
üìß beatriz.carvalho0804@gmail.com