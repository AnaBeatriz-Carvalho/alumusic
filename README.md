# üéµ AluMusic Insights - An√°lise de Feedback com IA

## 1. Apresenta√ß√£o e Resultados

**AluMusic Insights** √© uma plataforma de an√°lise de dados projetada para processar e extrair insights valiosos a partir de milhares de coment√°rios de ouvintes. A solu√ß√£o foi desenvolvida como parte de um desafio t√©cnico da Alura, com foco em **Python**, **Grandes Modelos de Linguagem (LLMs)** e arquitetura de sistemas escal√°veis.

O sistema ingere coment√°rios em lote, utiliza a API do **Google Gemini** para classifica√ß√£o de sentimento e extra√ß√£o de tags, e apresenta os resultados em um **dashboard privado** e em um **relat√≥rio p√∫blico em tempo real**. Nos testes de avalia√ß√£o, o sistema demonstrou uma **acur√°cia de 97%** na classifica√ß√£o de categorias em um dataset de 100 exemplos, validado por um pipeline de testes automatizado.

---

## ‚ú® Funcionalidades Principais

- **Ingest√£o Ass√≠ncrona de Dados**: Um endpoint de API REST (`/api/comentarios`) protegido por JWT que recebe lotes de coment√°rios e os enfileira para processamento em background.
- **Processamento com IA**: Utiliza√ß√£o do **Celery** e **Redis** para gerenciar uma fila de tarefas, onde workers processam cada coment√°rio individualmente, chamando a API do **Google Gemini** (`gemini-1.5-flash-latest`).
- **Dashboard Privado Interativo**: Uma interface moderna constru√≠da com **Streamlit**, protegida por login, que permite buscar, filtrar, visualizar o hist√≥rico de classifica√ß√µes e exportar os dados em formatos CSV e JSON.
- **Relat√≥rio P√∫blico em Tempo Real**: Uma p√°gina p√∫blica que exibe 6 visualiza√ß√µes de dados com os insights mais recentes, com um sistema de cache no Redis que garante que os dados sejam atualizados a cada 60 segundos.
- **Avalia√ß√£o de Performance da IA**: Um fluxo de avalia√ß√£o de ponta a ponta, automatizado com **Pytest**, que mede a qualidade da classifica√ß√£o do modelo.

---

## üèõÔ∏è Arquitetura e Estrutura

O projeto √© organizado de forma modular para separar as responsabilidades e facilitar a manuten√ß√£o. O sistema √© composto por servi√ßos containerizados e orquestrados com **Docker Compose**, seguindo uma arquitetura desacoplada e escal√°vel.

```mermaid
graph TD
    subgraph "Cliente Externo / Testes"
        A[Script de Carga / Pytest]
    end
    subgraph "Navegador do Usu√°rio"
        B[Dashboard Streamlit]
    end
    subgraph "Infraestrutura Docker"
        D[API Flask]
        E[Worker Celery]
        F[Banco de Dados PostgreSQL]
        G[Fila e Cache Redis]
    end
    subgraph "Servi√ßo Externo"
        H[API Google Gemini]
    end
    A -- JSON em lote c/ JWT --> D
    B -- Requisi√ß√µes REST c/ JWT --> D
    D -- Enfileira Tarefas --> G
    D -- Salva/L√™ Dados --> F
    D -- L√™/Escreve Cache do Relat√≥rio --> G
    E -- Pega Tarefas --> G
    E -- Chama API --> H
    E -- Salva Resultados --> F
```

---

## üõ†Ô∏è Tech Stack

- **Linguagem Principal**: Python (3.10+)
- **Backend**: Flask, SQLAlchemy
- **Frontend (Dashboard)**: Streamlit
- **Banco de Dados**: PostgreSQL
- **Fila e Cache**: Celery, Redis
- **Intelig√™ncia Artificial**: Google Gemini (via `google-generativeai`)
- **Visualiza√ß√£o de Dados**: Pandas, Matplotlib
- **Testes e M√©tricas**: Pytest, Scikit-learn
- **Containeriza√ß√£o**: Docker, Docker Compose

---

## üöÄ Como Executar o Projeto

### 1. Pr√©-requisitos

- **Docker**
- **Docker Compose**

### 2. Configura√ß√£o

Clone o reposit√≥rio e entre na branch correta:

```bash
git clone https://github.com/AnaBeatriz-Carvalho/alumusic.git
cd alumusic
```

Crie o arquivo `.env` a partir do exemplo:

```bash
cp .env.example .env
```

Abra o arquivo `.env` e preencha as vari√°veis, especialmente a sua `GOOGLE_API_KEY`.

### 3. Execu√ß√£o

Com o Docker em execu√ß√£o, suba todos os servi√ßos. O banco de dados ser√° criado e as migra√ß√µes ser√£o aplicadas automaticamente:

```bash
docker-compose up --build -d
```

Acesse o dashboard em [http://localhost:8501](http://localhost:8501) no seu navegador.

### 4. Avalia√ß√£o e M√©tricas

O projeto inclui um fluxo de avalia√ß√£o automatizado para medir a performance do modelo de classifica√ß√£o.

#### Comando de Execu√ß√£o

Para rodar os testes e gerar o relat√≥rio de m√©tricas, execute o seguinte comando √∫nico:

```bash
docker-compose exec api pytest -m e2e -sv
```

#### Resultado Esperado

O comando ir√° orquestrar todo o fluxo de teste e, ao final, imprimir um relat√≥rio detalhado no console, similar a este:

```
============================================================
 Relat√≥rio Final de Avalia√ß√£o da Pipeline de Classifica√ß√£o =
============================================================

>>> M√©tricas de Classifica√ß√£o de Categoria:
              precision    recall  f1-score   support
     CR√çTICA       1.00      0.97      0.98        31
      D√öVIDA       1.00      0.95      0.97        20
...
    accuracy                           0.97        98

>>> Matriz de Confus√£o (Real vs. Previsto):
               Prev: CR√çTICA  Prev: D√öVIDA ...
Real: CR√çTICA             30             0
Real: D√öVIDA               0            19

>>> M√©tricas de Extra√ß√£o de Tags:
Acur√°cia de Tags (correspond√™ncia exata): 10.20%
```

---

## ‚öñÔ∏è Principais Decis√µes de Design

- **API Ass√≠ncrona com Celery/Redis**: A escolha de uma arquitetura ass√≠ncrona foi fundamental para atender ao requisito de processamento de grandes lotes. A API pode aceitar centenas de coment√°rios instantaneamente, enfileirando o trabalho pesado para os workers.
- **Frontend Desacoplado com Streamlit**: Streamlit foi escolhido pela sua capacidade de criar rapidamente dashboards de dados interativos. A comunica√ß√£o via API REST mant√©m o frontend e o backend desacoplados, e o uso de um arquivo `.css` externo permitiu a cria√ß√£o de um design moderno e customizado.
- **Cache para Relat√≥rio em Tempo Real**: Optou-se por uma estrat√©gia de cache-on-demand na rota p√∫blica. A pr√≥pria API gera o relat√≥rio se o cache do Redis estiver expirado (60s). Isso simplifica a arquitetura (removendo a necessidade do Celery Beat para esta fun√ß√£o), mas ainda cumpre o requisito de atualiza√ß√£o.
- **Servi√ßo de LLM Isolado e Refinado**: Toda a l√≥gica de intera√ß√£o com o Gemini, incluindo a engenharia de prompt, foi centralizada no m√≥dulo `llm_service.py`. O prompt foi aprimorado com t√©cnicas de "Few-Shot Prompting" para aumentar a consist√™ncia e a acur√°cia na extra√ß√£o de tags.
- **Testes de Ponta a Ponta (E2E) com Pytest**: O fluxo de avalia√ß√£o foi desenhado para validar toda a pipeline: da ingest√£o na API, passando pela fila do Celery, o processamento do worker e a persist√™ncia no banco, fornecendo m√©tricas realistas.

---

## üó∫Ô∏è Endpoints Principais da API

- **POST** `/auth/register`: Registra um novo usu√°rio da equipe.
- **POST** `/auth/login`: Autentica um usu√°rio e retorna um token JWT.
- **POST** `/api/comentarios`: Recebe um lote de coment√°rios para processamento.
- **GET** `/api/comentarios`: Lista os coment√°rios processados, com suporte a filtros.
- **GET** `/api/comentarios/<uuid>`: Retorna os detalhes de um coment√°rio espec√≠fico.
- **GET** `/api/relatorio/semana`: Rota p√∫blica que retorna os dados do relat√≥rio em tempo real.

---

## ÔøΩÔ∏è Estrutura do c√≥digo

Resumo das pastas e arquivos mais relevantes (estado atual do branch `alumusic-refactor`):

- `app/` ‚Äî aplica√ß√£o Flask
    - `__init__.py` ‚Äî cria e configura a Flask app
    - `commands.py` ‚Äî comandos de CLI (ex.: gerar dados de teste)
    - `extensions.py` ‚Äî inicializa√ß√£o de extens√µes (db, jwt, migrate)
    - `api/` ‚Äî blueprint e rotas da API (`routes.py`)
    - `auth/` ‚Äî endpoints e l√≥gica de autentica√ß√£o (`auth.py`)
    - `core/` ‚Äî servi√ßos centrais
        - `llm_service.py` ‚Äî encapsula prompts e chamadas ao Google Gemini
        - `reporting_service.py` ‚Äî gera√ß√£o de dados/graphs para relat√≥rio
        - `email_service.py` ‚Äî arquivo marcador (envio de email removido; placeholder)
    - `models/` ‚Äî modelos SQLAlchemy (`user.py`, `comment.py`, `summary.py`)
    - `public/` ‚Äî rotas p√∫blicas (relat√≥rio)

- `tasks/` ‚Äî tarefas Celery
    - `process_comment.py` ‚Äî processamento por coment√°rio
    - `process_uploaded_file.py` ‚Äî processamento de uploads em lote
    - `reporting_tasks.py` ‚Äî tarefas de relat√≥rio/cache
    - `weekly_summary.py` ‚Äî tarefa agendada para resumo semanal

- `celery_app/` ‚Äî bootstrap e configura√ß√£o do Celery
- `streamlit_app.py` ‚Äî dashboard em Streamlit (frontend privado)
- `docker-compose.yml`, `Dockerfile` ‚Äî orquestra√ß√£o e imagem
- `migrations/` ‚Äî Alembic migrations
- `requirements.txt`, `pytest.ini` ‚Äî depend√™ncias e config de testes
- `tests/` ‚Äî su√≠te de testes E2E / unit√°rios (`tests/evals/` cont√©m datasets/evals)
- `assets/` ‚Äî CSS e recursos est√°ticos usados pelo Streamlit

Use essa vis√£o para encontrar rapidamente onde adicionar features ou criar testes.

## üîê Exemplo de `.env` (baseado nas configura√ß√µes do projeto)

Crie um arquivo `.env` na raiz com as vari√°veis abaixo (este √© um exemplo ‚Äî n√£o comite credenciais reais):

```ini
# Seguran√ßa
SECRET_KEY="uma_chave_secreta_local"
JWT_SECRET_KEY="uma_chave_jwt_local"

# Banco de dados Postgres
POSTGRES_USER=alumusic
POSTGRES_PASSWORD=alumusic
POSTGRES_DB=alumusic
# Quando rodando via Docker Compose, o host pode ser o nome do servi√ßo (ex: alumusic)
DATABASE_URL=postgresql://alumusic:alumusic@alumusic:5432/alumusic

# Celery (broker e backend de resultado)
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# Google Gemini API key (LLM)
GOOGLE_API_KEY="SUA_CHAVE_GOOGLE_GEMINI"

# (Opcional) SMTP - apenas se decidir reimplementar envio de e-mails
# SMTP_HOST=smtp.exemplo.com
# SMTP_PORT=587
# SMTP_USER=usuario
# SMTP_PASSWORD=senha
# EMAIL_FROM=no-reply@alumusic.com
```

Dicas:
- Para ambientes Docker Compose use nomes de servi√ßo como host (`alumusic`, `redis`).
- Para executar local sem Docker, ajuste `DATABASE_URL` para `localhost` e credenciais conforme seu Postgres local.


## ÔøΩüìû Contato

**Ana Beatriz Carvalho Oliveira**  
üìß beatriz.carvalho0804@gmail.com