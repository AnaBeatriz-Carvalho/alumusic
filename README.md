# üéµ AluMusic Insights ‚Äî README detalhado

Este README descreve o projeto AluMusic Insights com instru√ß√µes completas para execu√ß√£o local, testes/evals, arquitetura, decis√µes de design e notas operacionais. Est√° escrito em portugu√™s para facilitar o onboarding da equipe.

Sum√°rio
- Apresenta√ß√£o e resultados do case
- Como executar o projeto (passo a passo)
- Como rodar testes e evals
- Principais decis√µes de design
- Estrutura do reposit√≥rio e refer√™ncias r√°pidas

## Apresenta√ß√£o do projeto e resultados do case

AluMusic Insights √© uma aplica√ß√£o para ingest√£o, processamento e visualiza√ß√£o de coment√°rios de ouvintes. O objetivo do case foi demonstrar uma pipeline de processamento ass√≠ncrono que combina infra tradicional (Flask, PostgreSQL, Celery, Redis) com LLMs (Google Gemini) para:

- Classificar categoria (ex.: ELOGIO, CR√çTICA, SUGEST√ÉO, D√öVIDA, SPAM).
- Extrair tags funcionais (c√≥digos de t√≥picos extra√≠dos por IA).
- Apresentar um dashboard privado para curadores e um relat√≥rio p√∫blico atualizado periodicamente.

Resultados esperados do case:

- Pipeline E2E capaz de processar lotes grandes sem bloquear a API (Celery + Redis).
- Classifica√ß√£o autom√°tica com m√©tricas geradas por scripts de avalia√ß√£o (Acur√°cia, Precis√£o, Recall, F1-Score, Matriz de Confus√£o).
- Dashboard interativo (Streamlit) com filtros, exporta√ß√£o CSV/JSON e autorefresh para curadoria.

## Passo a passo detalhado para executar o projeto

Pr√©-requisitos
- Docker e Docker Compose instalados localmente.
- (Opcional) Python 3.10+ se quiser rodar partes fora de cont√™iner.

1) Clone o reposit√≥rio

   git clone <URL_DO_REPOSITORIO>
   cd alumusic

2) Vari√°veis de ambiente

Crie um arquivo `.env` na raiz com as vari√°veis necess√°rias. N√£o h√° um arquivo `.env.example` no reposit√≥rio; seguem as vari√°veis m√≠nimas necess√°rias para rodar:

   SECRET_KEY="uma_chave_secreta"
   JWT_SECRET_KEY="uma_chave_jwt"
   POSTGRES_USER=alumusic
   POSTGRES_PASSWORD=alumusic
   POSTGRES_DB=alumusic
   DATABASE_URL=postgresql://alumusic:alumusic@alumusic:5432/alumusic
   CELERY_BROKER_URL=redis://redis:6379/0
   CELERY_RESULT_BACKEND=redis://redis:6379/0
   GOOGLE_API_KEY="SUA_CHAVE_GOOGLE_GEMINI"

3) Build e run com Docker Compose (recomendado)

Suba todos os servi√ßos com:

   docker-compose up --build -d

O compose j√° define os servi√ßos principais:

- api: servi√ßo Flask + Gunicorn (porta mapeada 5001:5000)
- worker: Celery worker
- streamlit: frontend privado (porta 8501)
- alumusic: PostgreSQL
- redis: Redis para broker/result backend e cache

4) Acesse as interfaces

- Dashboard (privado): http://localhost:8501 ‚Äî registre um usu√°rio na aba "Registrar" e fa√ßa login.
- API (interno/externo): http://localhost:5001 (o container exp√µe 5000 internamente; o compose mapeia para 5001 localmente).

5) Logs e troubleshooting b√°sicos

Visualizar logs do API:

   docker-compose logs -f api

Verificar status dos cont√™ineres:

   docker ps -a

Se o PostgreSQL falhar no healthcheck, confirme as vari√°veis `POSTGRES_*` e se o volume n√£o est√° corrompido.

## Como rodar testes e evals

Testes unit√°rios e de integra√ß√£o usam Pytest. O reposit√≥rio inclui um teste E2E para avaliar a pipeline de classifica√ß√£o em `tests/evals/test_classification_pipeline.py`.

Passos recomendados para rodar os evals em ambiente replic√°vel (dentro do compose):

1) Assegure que os servi√ßos estejam up (veja acima).
2) Garanta que exista um usu√°rio de teste com as credenciais definidas em `tests/evals/test_classification_pipeline.py` (por padr√£o `email@teste.com` / `teste123`). Voc√™ pode registrar via dashboard Streamlit ou via endpoint `/auth/register`.
3) Execute os testes E2E:

   docker-compose exec api pytest -m e2e -sv

O teste realiza o seguinte: carrega o arquivo `tests/evals/dataset.json`, envia coment√°rios para a API, aguarda o processamento ass√≠ncrono (o teste dorme por ~180s) e, em seguida, consulta o banco para comparar previs√µes com o gabarito. O resultado impresso inclui classification_report e matriz de confus√£o.

Rodando testes localmente (sem Docker)

1) Crie e ative um virtualenv com Python 3.10+.
2) Instale depend√™ncias:

   pip install -r requirements.txt

3) Configure vari√°veis de ambiente (como acima) e execute as migra√ß√µes:

   flask db migrate && flask db upgrade

4) Execute os testes:

   pytest -m e2e -sv

Observa√ß√£o: rodar E2E fora do Docker exige que PostgreSQL e Redis tamb√©m estejam dispon√≠veis localmente e configurados conforme `DATABASE_URL` e `CELERY_BROKER_URL`.

## Principais decis√µes de design

Aqui est√£o as decis√µes arquiteturais mais relevantes e por que foram adotadas:

- Assincronismo (Celery + Redis): permite ingest√£o massiva sem bloquear a API. A escolha reduz a lat√™ncia percebida pelo cliente e facilita escalabilidade horizontal dos workers.
- Desacoplamento Frontend/Backend: Streamlit consome a API REST (Flask). Isso torna a interface r√°pida de desenvolver e independente da l√≥gica de backend.
- Servi√ßo isolado para LLM (`core/llm_service.py`): concentra prompts, parsing e chamadas ao Google Gemini num √∫nico m√≥dulo, tornando testes, substitui√ß√µes de modelo e manuten√ß√£o mais f√°ceis.
- Cache simples para relat√≥rios: o uso do Redis como cache com TTL (atualiza√ß√£o a cada 60s) reduz a carga no banco e mant√©m o relat√≥rio "quase em tempo real".
- Testes E2E que cobrem a pipeline completa: validar somente fun√ß√µes do LLM n√£o √© suficiente; os E2E garantem que enfileiramento, workers e persist√™ncia tamb√©m funcionem.

## Estrutura do reposit√≥rio (resumo r√°pido)

- `app/` ‚Äî pacote principal (API, auth, modelos, comandos, extens√µes)
- `core/` ‚Äî servi√ßos internos (llm_service.py, email_service.py, reporting_service.py)
- `tasks/` ‚Äî l√≥gica de processamento ass√≠ncrono (ex.: `process_comment.py`)
- `streamlit_app.py` ‚Äî dashboard Streamlit
- `docker-compose.yml`, `Dockerfile` ‚Äî orquestra√ß√£o e build
- `requirements.txt` ‚Äî depend√™ncias Python
- `tests/` ‚Äî testes, incluindo E2E de avalia√ß√£o em `tests/evals`

## Notas operacionais e considera√ß√µes finais

- Chave do Google Gemini: mantenha em segredo e n√£o a commit no reposit√≥rio.
- Migra√ß√µes: o compose j√° executa `flask db migrate && flask db upgrade` antes de iniciar o gunicorn no servi√ßo `api`.
- Timeout de processamento nos testes: o teste E2E usa uma espera de ~180s; ajuste conforme o desempenho da sua m√°quina/infra.

